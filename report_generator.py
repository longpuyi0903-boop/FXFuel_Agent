# report_generator.py - æŠ¥å‘Šç”Ÿæˆå™¨

from typing import Optional, Dict, Any
import json
import re

from config import get_deepseek_client, DEEPSEEK_MODEL, REPORT_CONFIG, CORE_INDICATORS, DEFAULT_TOLERANCE
from data_retriever import DataContext, retrieve_all_data
from prompt_templates import get_report_prompt, get_followup_prompt, get_validation_prompt


class ReportGenerator:
    """å¤–æ±‡å‘¨æŠ¥ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.client = None  # å»¶è¿Ÿåˆå§‹åŒ–
        self.data_context: Optional[DataContext] = None
        self.generated_report: Optional[str] = None
        self.validation_result: Optional[Dict] = None
    
    def _get_client(self):
        """è·å– DeepSeek å®¢æˆ·ç«¯ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if self.client is None:
            self.client = get_deepseek_client()
        return self.client
    
    def collect_data(self) -> DataContext:
        """é‡‡é›†æ•°æ®"""
        self.data_context = retrieve_all_data()
        return self.data_context
    
    def generate_report(self, data_context: Optional[DataContext] = None) -> str:
        """
        ç”Ÿæˆå‘¨æŠ¥
        
        Args:
            data_context: æ•°æ®ä¸Šä¸‹æ–‡ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨é‡‡é›†
            
        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Š Markdown æ–‡æœ¬
        """
        # å¦‚æœæ²¡æœ‰æä¾›æ•°æ®ï¼Œåˆ™é‡‡é›†
        if data_context is None:
            if self.data_context is None:
                self.collect_data()
            data_context = self.data_context
        else:
            self.data_context = data_context
        
        # è·å–æç¤ºè¯
        data_json = data_context.to_json()
        prompts = get_report_prompt(data_json)
        
        # è°ƒç”¨ LLM
        client = self._get_client()
        response = client.chat.completions.create(
            model=DEEPSEEK_MODEL,
            messages=[
                {"role": "system", "content": prompts["system"]},
                {"role": "user", "content": prompts["user"]}
            ],
            max_tokens=REPORT_CONFIG["max_tokens"],
            temperature=REPORT_CONFIG["temperature"]
        )
        
        self.generated_report = response.choices[0].message.content
        return self.generated_report
    
    def answer_followup(self, question: str) -> str:
        """
        å›ç­”è¿½é—®
        
        Args:
            question: ç”¨æˆ·çš„è¿½é—®é—®é¢˜
            
        Returns:
            å›ç­”æ–‡æœ¬
        """
        if self.data_context is None or self.generated_report is None:
            return "è¯·å…ˆç”ŸæˆæŠ¥å‘Šå†è¿›è¡Œè¿½é—®ã€‚"
        
        # è·å–è¿½é—®æç¤ºè¯
        prompts = get_followup_prompt(
            data_json=self.data_context.to_json(),
            report=self.generated_report,
            question=question
        )
        
        # è°ƒç”¨ LLM
        client = self._get_client()
        response = client.chat.completions.create(
            model=DEEPSEEK_MODEL,
            messages=[
                {"role": "system", "content": prompts["system"]},
                {"role": "user", "content": prompts["user"]}
            ],
            max_tokens=2000,
            temperature=REPORT_CONFIG["temperature"]
        )
        
        return response.choices[0].message.content
    
    def validate_report(self) -> Dict[str, Any]:
        """
        æ ¡éªŒæŠ¥å‘Šï¼ˆæ£€æµ‹å¹»è§‰ï¼‰- ä½¿ç”¨ç¡¬ç¼–ç æ ¡éªŒé€»è¾‘
        
        Returns:
            æ ¡éªŒç»“æœå­—å…¸
        """
        if self.data_context is None or self.generated_report is None:
            return {"error": "æ²¡æœ‰å¯æ ¡éªŒçš„æŠ¥å‘Š"}
        
        # å°† DataContext è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆä¸ streamlit_app.py ä¸­çš„æ ¼å¼ä¸€è‡´ï¼‰
        ctx_dict = {
            "USDCNY_MID": self.data_context.cny.get("usdcny_mid"),
            "USDCNH_CLOSE": self.data_context.cny.get("usdcnh_spot"),
            "CNY_SPREAD": self.data_context.cny.get("cny_spread"),
            "USDHKD": self.data_context.hkd.get("usdhkd"),
            "HIBOR_OVERNIGHT": self.data_context.hkd.get("hibor_overnight"),
            "HKD_USD_SPREAD": self.data_context.hkd.get("hkd_usd_spread"),
            "EURUSD": self.data_context.global_fx.get("eurusd"),
            "USDJPY": self.data_context.global_fx.get("usdjpy"),
            "DXY": self.data_context.global_fx.get("dxy"),
            "US10Y_YIELD": self.data_context.macro.get("us10y"),
            "US2Y_YIELD": self.data_context.macro.get("us2y"),
            "VIX_LAST": self.data_context.macro.get("vix"),
        }
        
        # è°ƒç”¨ç¡¬ç¼–ç æ ¡éªŒå‡½æ•°
        self.validation_result = verify_numbers_hard_code(ctx_dict, self.generated_report)
        return self.validation_result
    
    def get_data_summary(self) -> str:
        """è·å–æ•°æ®æ‘˜è¦ï¼ˆç”¨äºå±•ç¤ºï¼‰"""
        if self.data_context is None:
            return "å°šæœªé‡‡é›†æ•°æ®"
        
        ctx = self.data_context
        summary_parts = []
        
        # äººæ°‘å¸æ•°æ®æ‘˜è¦
        if ctx.cny:
            cny_items = []
            if ctx.cny.get("usdcny_mid_latest"):
                cny_items.append(f"ä¸­é—´ä»·: {ctx.cny['usdcny_mid_latest']}")
            if ctx.cny.get("usdcnh_spot"):
                cny_items.append(f"ç¦»å²¸: {ctx.cny['usdcnh_spot']}")
            if ctx.cny.get("usdcny_mid_weekly_high") and ctx.cny.get("usdcny_mid_weekly_low"):
                cny_items.append(f"æœ¬å‘¨åŒºé—´: {ctx.cny['usdcny_mid_weekly_low']}-{ctx.cny['usdcny_mid_weekly_high']}")
            if cny_items:
                summary_parts.append(f"**äººæ°‘å¸**: " + " | ".join(cny_items))
        
        # æ¸¯å…ƒæ•°æ®æ‘˜è¦
        if ctx.hkd:
            hkd_items = []
            if ctx.hkd.get("usdhkd_spot"):
                hkd_items.append(f"USD/HKD: {ctx.hkd['usdhkd_spot']}")
            if ctx.hkd.get("lers_position"):
                hkd_items.append(f"åŒºé—´: {ctx.hkd['lers_position']}")
            if ctx.hkd.get("hibor_overnight"):
                hkd_items.append(f"HIBORéš”å¤œ: {ctx.hkd['hibor_overnight']}%")
            if hkd_items:
                summary_parts.append(f"**æ¸¯å…ƒ**: " + " | ".join(hkd_items))
        
        # å…¨çƒå¸‚åœºæ‘˜è¦
        if ctx.global_fx:
            global_items = []
            if ctx.global_fx.get("dxy"):
                global_items.append(f"DXY: {ctx.global_fx['dxy']}")
            if ctx.global_fx.get("us10y_yield"):
                global_items.append(f"10Y: {ctx.global_fx['us10y_yield']}%")
            if ctx.global_fx.get("vix"):
                global_items.append(f"VIX: {ctx.global_fx['vix']}")
            if global_items:
                summary_parts.append(f"**å…¨çƒ**: " + " | ".join(global_items))
        
        # æ•°æ®é‡‡é›†çŠ¶æ€
        status = f"\n\nğŸ“Š æ•°æ®ç‚¹: {ctx._count_data_points()} | âš ï¸ é”™è¯¯: {len(ctx.errors)}"
        
        return "\n".join(summary_parts) + status if summary_parts else "æ•°æ®é‡‡é›†ä¸­..."
    
    def get_raw_data(self) -> str:
        """è·å–åŸå§‹æ•°æ® JSONï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        if self.data_context is None:
            return "{}"
        return self.data_context.to_json()


# ============================================================================
# ç¡¬ç¼–ç æ ¡éªŒå‡½æ•°
# ============================================================================

def verify_numbers_hard_code(data_context: Dict[str, Any], report_text: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨ç¡¬ç¼–ç é€»è¾‘æ ¡éªŒæŠ¥å‘Šä¸­çš„æ•°å€¼æ˜¯å¦ä¸åŸå§‹æ•°æ®ä¸€è‡´
    
    Args:
        data_context: æ•°æ®å­—å…¸ï¼Œé”®åä¸º CORE_INDICATORS ä¸­å®šä¹‰çš„ data_field
        report_text: ç”Ÿæˆçš„æŠ¥å‘Šæ–‡æœ¬
        
    Returns:
        æ ¡éªŒç»“æœå­—å…¸ï¼ŒåŒ…å« is_valid å’Œ audit_log
    """
    audit_log = []
    is_valid = True
    
    # æµ®ç‚¹æ•°æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ”¯æŒè´Ÿæ•°ï¼‰
    float_pattern = r'-?\d+\.?\d*'
    
    # éå†æ‰€æœ‰æ ¸å¿ƒæŒ‡æ ‡
    for indicator_name, config in CORE_INDICATORS.items():
        keywords = config["keywords"]
        data_field = config["data_field"]
        tolerance = config.get("tolerance", DEFAULT_TOLERANCE)
        
        # è·å–åŸå§‹æ•°æ®å€¼
        raw_val = data_context.get(data_field)
        
        # å¦‚æœåŸå§‹æ•°æ®ä¸º Noneï¼Œæ ‡è®°ä¸º WARNINGï¼ˆæ•°æ®ç¼ºå¤±ï¼‰ï¼Œä¸è¿›è¡Œæ¯”å¯¹
        if raw_val is None:
            audit_log.append({
                "item": indicator_name,
                "report_val": None,
                "raw_val": None,
                "diff": None,
                "status": "WARNING",
                "msg": "æ•°æ®ç¼ºå¤±"
            })
            continue
        
        # å°è¯•ä»æŠ¥å‘Šä¸­æå–æ•°å€¼
        report_val = None
        matched_keyword = None
        
        for keyword in keywords:
            # åœ¨æŠ¥å‘Šä¸­æœç´¢å…³é”®è¯ä½ç½®
            keyword_match = re.search(re.escape(keyword), report_text, re.IGNORECASE)
            
            if keyword_match:
                # ä»å…³é”®è¯ç»“æŸä½ç½®å¼€å§‹ï¼Œå‘åæœç´¢30å­—ç¬¦å†…çš„æµ®ç‚¹æ•°
                keyword_end_pos = keyword_match.end()
                search_text = report_text[keyword_end_pos:keyword_end_pos + 50]  # å‘åæœç´¢50å­—ç¬¦
                
                # åœ¨æœç´¢æ–‡æœ¬ä¸­æŸ¥æ‰¾æµ®ç‚¹æ•°ï¼ˆé¿å…åŒ¹é…å…³é”®è¯æœ¬èº«åŒ…å«çš„æ•°å­—ï¼‰
                # ä¼˜å…ˆåŒ¹é…å¸¦å°æ•°ç‚¹çš„æ•°å­—ï¼ˆæ›´å¯èƒ½æ˜¯å®é™…æ•°å€¼ï¼Œè€Œä¸æ˜¯å¹´ä»½æˆ–ç¼–å·ï¼‰
                decimal_pattern = r'-?\d+\.\d+'
                number_matches = re.findall(decimal_pattern, search_text)
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¸¦å°æ•°ç‚¹çš„æ•°å­—ï¼Œå†å°è¯•åŒ¹é…æ•´æ•°
                if not number_matches:
                    number_matches = re.findall(float_pattern, search_text)
                
                if number_matches:
                    # å°è¯•æ¯ä¸ªæ•°å€¼ï¼Œé€‰æ‹©æœ€æ¥è¿‘åŸå§‹å€¼çš„é‚£ä¸ª
                    best_val = None
                    min_diff = float('inf')
                    
                    for num_str in number_matches:
                        try:
                            candidate_val = float(num_str)
                            # è®¡ç®—ä¸åŸå§‹å€¼çš„å·®å¼‚
                            diff = abs(candidate_val - raw_val)
                            
                            # é€‰æ‹©å·®å¼‚æœ€å°çš„æ•°å€¼ï¼ˆä½†ä¹Ÿè¦åœ¨åˆç†èŒƒå›´å†…ï¼Œå·®å¼‚è¶…è¿‡10çš„å¯èƒ½æ˜¯è¯¯åŒ¹é…ï¼‰
                            if diff < min_diff and diff < 10:
                                min_diff = diff
                                best_val = candidate_val
                        except ValueError:
                            continue
                    
                    if best_val is not None:
                        report_val = best_val
                        matched_keyword = keyword
                        break  # æ‰¾åˆ°åŒ¹é…å°±é€€å‡ºå…³é”®è¯å¾ªç¯
        
        # åˆ¤æ–­ç»“æœ
        if report_val is None:
            # æœªåœ¨æŠ¥å‘Šä¸­æåŠ
            audit_log.append({
                "item": indicator_name,
                "report_val": None,
                "raw_val": raw_val,
                "diff": None,
                "status": "WARNING",
                "msg": "æœªåœ¨æŠ¥å‘Šä¸­æåŠ"
            })
            # WARNING ä¸å½±å“ is_valid çŠ¶æ€
        else:
            # è¿›è¡Œæ•°å€¼æ¯”å¯¹
            diff = abs(report_val - raw_val)
            
            if diff <= tolerance:
                status = "PASS"
                msg = f"ä¸€è‡´ï¼ˆå·®å¼‚ {diff:.4f} <= å®¹å·® {tolerance}ï¼‰"
            else:
                status = "FAIL"
                msg = f"å·®å¼‚ {diff:.4f} > å®¹å·® {tolerance}"
                is_valid = False  # æœ‰ä¸€ä¸ªå¤±è´¥å°±æ ‡è®°ä¸ºæ— æ•ˆ
            
            audit_log.append({
                "item": indicator_name,
                "report_val": report_val,
                "raw_val": raw_val,
                "diff": round(diff, 4),
                "status": status,
                "msg": msg
            })
    
    return {
        "is_valid": is_valid,
        "audit_log": audit_log
    }


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def generate_fx_report() -> tuple[str, DataContext]:
    """
    ä¸€é”®ç”Ÿæˆå¤–æ±‡å‘¨æŠ¥
    
    Returns:
        (æŠ¥å‘Šæ–‡æœ¬, æ•°æ®ä¸Šä¸‹æ–‡)
    """
    generator = ReportGenerator()
    generator.collect_data()
    report = generator.generate_report()
    return report, generator.data_context


# ============================================================================
# æµ‹è¯•å…¥å£
# ============================================================================

if __name__ == "__main__":
    print("="*60)
    print("å¤–æ±‡å‘¨æŠ¥ç”Ÿæˆå™¨æµ‹è¯•")
    print("="*60)
    
    generator = ReportGenerator()
    
    # 1. é‡‡é›†æ•°æ®
    print("\n[1] é‡‡é›†æ•°æ®...")
    ctx = generator.collect_data()
    print(generator.get_data_summary())
    
    # 2. ç”ŸæˆæŠ¥å‘Š
    print("\n[2] ç”ŸæˆæŠ¥å‘Š...")
    report = generator.generate_report()
    print("\n" + "-"*60)
    print(report)
    print("-"*60)
    
    # 3. æ ¡éªŒæŠ¥å‘Š
    print("\n[3] æ ¡éªŒæŠ¥å‘Š...")
    validation = generator.validate_report()
    print(json.dumps(validation, ensure_ascii=False, indent=2))
    
    # 4. æµ‹è¯•è¿½é—®
    print("\n[4] æµ‹è¯•è¿½é—®...")
    answer = generator.answer_followup("æœ¬å‘¨äººæ°‘å¸ä¸­é—´ä»·å…·ä½“æ˜¯å¤šå°‘ï¼Ÿ")
    print(answer)
